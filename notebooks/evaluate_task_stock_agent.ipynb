{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model for US Stock Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import vectorbt as vbt\n",
    "import gymnasium as gym\n",
    "from copy import deepcopy\n",
    "from stock_env.common.common_utils import create_performance, plot_trade_log_v2\n",
    "from stock_env.envs import *\n",
    "from stock_env.common.evaluation import evaluate_agent, play_an_episode\n",
    "from stock_env.algos.agent import MetaAgent\n",
    "from stock_env.common.common_utils import open_config\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"SP500-v0\"\n",
    "state_dict_path = \"../model/maml_sp500_20221217_141044.pth\"\n",
    "num_tasks = num_envs = 5\n",
    "env_config = open_config(\"../configs/envs.yaml\", env_id=env_id)\n",
    "\n",
    "_env = MetaVectorEnv([lambda: gym.make(env_id) for _ in range(1)])\n",
    "meta_agent = MetaAgent(_env)\n",
    "\n",
    "# meta agent\n",
    "meta_agent.load_state_dict(th.load(state_dict_path))\n",
    "meta_agent.eval()\n",
    "\n",
    "# random\n",
    "random_agent = deepcopy(meta_agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on random period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_envs = num_tasks = 5\n",
    "\n",
    "eval_envs = MetaVectorEnv([lambda: gym.make(env_id) for _ in range(num_envs)])\n",
    "eval_envs.train(False)\n",
    "\n",
    "tasks = eval_envs.sample_task(num_tasks)\n",
    "for env, task in zip(eval_envs.envs, tasks):\n",
    "    env.reset_task(task)\n",
    "\n",
    "mean, std = evaluate_agent(meta_agent, eval_envs, n_eval_episodes=100)\n",
    "print(f\"Mean reward: {mean:.2f} +/- {std: .2f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation on specific stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "# prepare tables\n",
    "metrics = [\n",
    "    \"annual_return\",\n",
    "    \"cum_returns_final\",\n",
    "    \"sharpe_ratio\",\n",
    "    \"max_drawdown\",\n",
    "    \"annual_volatility\",\n",
    "    \"value_at_risk\",\n",
    "]\n",
    "agents = {\n",
    "    \"MAML\": meta_agent,\n",
    "    \"Random\": random_agent,\n",
    "}\n",
    "N_TASKS = 10\n",
    "\n",
    "# Main process\n",
    "single_eval_envs = MetaVectorEnv([lambda: gym.make(env_id) for _ in range(1)])\n",
    "single_eval_envs.train(False)\n",
    "tasks = single_eval_envs.sample_task(N_TASKS)\n",
    "\n",
    "perf_df = pd.DataFrame(\n",
    "    index=pd.MultiIndex.from_product([tasks, metrics]), columns=agents.keys()\n",
    ")\n",
    "for task in tasks:\n",
    "    single_eval_envs.reset_task(task)\n",
    "\n",
    "    for agent_key, agent in agents.items():\n",
    "        # run model to get detailed information in the enviroment\n",
    "        info = play_an_episode(agent, single_eval_envs)\n",
    "        df = info[\"final_info\"][0][\"final_history\"]\n",
    "        returns = df.set_index(\"time\")[\"portfolio_value\"].pct_change()\n",
    "        perf = create_performance(returns, plot=False)\n",
    "\n",
    "        for metric, value in perf.items():\n",
    "            perf_df.loc[(task, metric), agent_key] = round(value * 100, 2)\n",
    "\n",
    "    # buy and hold performance\n",
    "    holding_returns = (\n",
    "        vbt.Portfolio.from_holding(df.close, init_cash=env_config.init_cash)\n",
    "        .value()\n",
    "        .pct_change()\n",
    "    )\n",
    "    perf = create_performance(holding_returns, plot=False)\n",
    "    for metric, value in perf.items():\n",
    "        perf_df.loc[(task, metric), \"Buy-n-Hold\"] = round(value * 100, 2)\n",
    "perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df[\"is_better\"] = perf_df[\"MAML\"] > perf_df[\"Buy-n-Hold\"]\n",
    "perf_df.loc[(tasks, (\"sharpe_ratio\", \"max_drawdown\")), :].sort_values(\n",
    "    \"MAML\", ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_trade_log_v2(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with buy-and-hold strategy and feature strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio value from hodling\n",
    "df[\"pv_from_holding\"] = vbt.Portfolio.from_holding(\n",
    "    df.close, init_cash=env_config.init_cash\n",
    ").value()\n",
    "df = df.set_index(\"time\")\n",
    "ticker = df[\"ticker_x\"].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.update_layout(width=800, height=500)\n",
    "fig.update_layout(title=f\"Buy-n-Hold Comparision, Ticker: {ticker}\", title_x=0.5)\n",
    "fig.update_xaxes(title_text=\"Date\")\n",
    "fig.update_yaxes(title_text=\"Portfolio Value ($)\")\n",
    "\n",
    "df[\"portfolio_value\"].vbt.plot_against(\n",
    "    other=df[\"pv_from_holding\"],\n",
    "    other_trace_kwargs=dict(\n",
    "        line=dict(width=2, color=\"dimgray\"), mode=\"lines\", name=\"Buy-n-Hold\"\n",
    "    ),\n",
    "    trace_kwargs=dict(\n",
    "        mode=\"lines+markers\",\n",
    "        line=dict(width=3, color=\"lightslategray\"),\n",
    "        name=\"MAML\",\n",
    "    ),\n",
    "    pos_trace_kwargs=dict(fillcolor=\"palegreen\"),\n",
    "    neg_trace_kwargs=dict(fillcolor=\"salmon\"),\n",
    "    fig=fig,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After refactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_env.algos.agent import Agent\n",
    "from stock_env.envs import *\n",
    "from stock_env.common.common_utils import open_config\n",
    "from stock_env.common.env_utils import make_vec_env\n",
    "import torch as th\n",
    "from stock_env.common.common_utils import create_performance, plot_trade_log_v2\n",
    "from stock_env.common.evaluation import play_an_episode\n",
    "from stock_env.common.common_utils import open_config\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def buy_and_hold_plot(df, algo_name, init_cash=1000000):\n",
    "    import vectorbt as vbt\n",
    "    \n",
    "    # portfolio value from hodling\n",
    "    df[\"pv_from_holding\"] = vbt.Portfolio.from_holding(\n",
    "        df.close, init_cash=init_cash\n",
    "    ).value()\n",
    "    df = df.set_index(\"time\")\n",
    "    ticker = df[\"ticker_x\"].unique()[0]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.update_layout(width=800, height=500)\n",
    "    fig.update_layout(title=f\"Buy-n-Hold Comparision, Ticker: {ticker}\", title_x=0.5)\n",
    "    fig.update_xaxes(title_text=\"Date\")\n",
    "    fig.update_yaxes(title_text=\"Portfolio Value ($)\")\n",
    "\n",
    "    df[\"portfolio_value\"].vbt.plot_against(\n",
    "        other=df[\"pv_from_holding\"],\n",
    "        other_trace_kwargs=dict(\n",
    "            line=dict(width=2, color=\"dimgray\"), mode=\"lines\", name=\"Buy-n-Hold\"\n",
    "        ),\n",
    "        trace_kwargs=dict(\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(width=3, color=\"lightslategray\"),\n",
    "            name=\"MAML\",\n",
    "        ),\n",
    "        pos_trace_kwargs=dict(fillcolor=\"palegreen\"),\n",
    "        neg_trace_kwargs=dict(fillcolor=\"salmon\"),\n",
    "        fig=fig,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"SP500-v0\"\n",
    "model_path = \"../model/ppo_sp500_20221230_000928.pth\"\n",
    "config_path = \"../configs/ppo.yaml\"\n",
    "\n",
    "# setting up\n",
    "envs = make_vec_env(env_id, num_envs=1, task=\"AAPL\")\n",
    "args = open_config(\"../configs/ppo.yaml\", env_id=env_id)\n",
    "agent = Agent(envs, hiddens=args.hiddens)\n",
    "agent.load_state_dict(th.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "envs.train(False)\n",
    "info = play_an_episode(agent, envs)\n",
    "df = info[\"final_info\"][0][\"final_history\"]\n",
    "returns = df.set_index(\"time\")[\"portfolio_value\"].pct_change()\n",
    "results = create_performance(returns)\n",
    "plot_trade_log_v2(df)\n",
    "\n",
    "buy_and_hold_plot(df, \"MAML\", init_cash=envs.envs[0].init_cash)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tradingenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:13:39) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "faa7f68368d9c9f740356072b5cc858737f0635c1c0b552678cb52f36bb31777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
