{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81d808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import itertools\n",
    "from stable_baselines3.dqn import DQN\n",
    "\n",
    "\n",
    "def safe_divide(a, b):\n",
    "    return np.divide(a, b, out=np.zeros_like(a), where=b!=0)\n",
    "\n",
    "def moving_average(iterable, n=3):\n",
    "    # moving_average([40, 30, 50, 46, 39, 44]) --> 40.0 42.0 45.0 43.0\n",
    "    # http://en.wikipedia.org/wiki/Moving_average\n",
    "    it = iter(iterable)\n",
    "    d = deque(itertools.islice(it, n-1))\n",
    "    print(next(it))\n",
    "    d.appendleft(0)\n",
    "    s = sum(d)\n",
    "    print(d)\n",
    "    print(s)\n",
    "    for elem in it:\n",
    "        s += elem - d.popleft()\n",
    "        d.append(elem)\n",
    "        yield s / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2146662",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "h = 5\n",
    "pe = 50\n",
    "sig = 0.1\n",
    "\n",
    "# trading params\n",
    "tick_size = 0.1\n",
    "lot_size = 100\n",
    "n_action = 5\n",
    "M = 10\n",
    "\n",
    "# calculated params\n",
    "dt = 1 / n\n",
    "lmbda = np.log(2) / h\n",
    "action_space = lot_size * np.arange(-n_action, n_action+1)\n",
    "holdings = np.arange(-M, M+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bd434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        window_size: int = 1,\n",
    "        n_action: int = 5,\n",
    "        tick_size: float = 0.1,\n",
    "        lot_size: int = 100,\n",
    "        start_nav: float = 1e6,\n",
    "        kappa: float = 0.02,\n",
    "    ):\n",
    "\n",
    "        self.seed()\n",
    "        self.df = df\n",
    "        self.window_size = window_size\n",
    "        self.window = deque(maxlen=self.window_size)\n",
    "        self.max_asset = self.df.shape[1]\n",
    "        self.shape = (window_size, self.max_asset)\n",
    "        self.tick_size = tick_size\n",
    "        self.lot_size = lot_size\n",
    "        self.kappa = kappa\n",
    "        self.start_nav = start_nav\n",
    "        self.shares = np.arange(-200, 300, 100)\n",
    "\n",
    "        # spaces\n",
    "        self.n_action = n_action\n",
    "        self.action_space = spaces.Discrete(self.n_action)\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=self.shape, dtype=np.float32)\n",
    "\n",
    "        # episode\n",
    "        self._start_tick = self.window_size - 1\n",
    "        self._end_tick = self.df.shape[0] - 1\n",
    "        self._current_tick = None\n",
    "        self._last_trade_tick = None\n",
    "        self._first_rendering = None\n",
    "        self.done = None\n",
    "        # self.position = None\n",
    "        # self.position_history = None\n",
    "        self.total_reward = None\n",
    "        self.total_profit = None\n",
    "        self.history = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self):\n",
    "        self._current_tick = self._start_tick\n",
    "        self._first_rendering = True\n",
    "        self.window.clear()\n",
    "        self.window.extend(self.df.iloc[:self.window_size].to_numpy())\n",
    "        self.done = False\n",
    "        self.total_reward = 0\n",
    "        self.total_profit = 0  # unit\n",
    "        self.history = {\n",
    "            'actions': (self.window_size-1) * [None],\n",
    "            'shares': (self.window_size-1) * [0], #TODO\n",
    "            'delta_vt': (self.window_size-1) * [0],\n",
    "            'total_reward': (self.window_size-1) * [self.total_reward],\n",
    "            'total_profit': (self.window_size-1) * [self.total_profit]\n",
    "        }\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action: int):\n",
    "        self._current_tick += 1\n",
    "        new_prices = self.df.iloc[self._current_tick, :].item()\n",
    "        \n",
    "        self.done = False\n",
    "        if self._current_tick == self._end_tick:\n",
    "            self.done = True\n",
    "        \n",
    "        delta_vt = self.delta_vt(action, new_prices)\n",
    "        step_reward = self._calculate_reward(delta_vt)\n",
    "        self.total_reward += step_reward\n",
    "        self.total_profit += delta_vt\n",
    "        \n",
    "        # always update history last\n",
    "        # dont move this row\n",
    "        self.window.append(new_prices)\n",
    "        info = dict(\n",
    "            actions = action,\n",
    "            delta_vt = delta_vt,\n",
    "            total_reward = self.total_reward,\n",
    "            total_profit = self.total_profit,\n",
    "            shares = self._decode_action(action))\n",
    "        self._update_history(info)\n",
    "\n",
    "        return new_prices, step_reward, self.done, info\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # process window\n",
    "        return self.window[-1]\n",
    "\n",
    "    def _update_history(self, info):\n",
    "        if not self.history:\n",
    "            self.history = {key: [] for key in info.keys()}\n",
    "\n",
    "        for key, value in info.items():\n",
    "            self.history[key].append(value)\n",
    "    \n",
    "    def spread_cost(self, dn: np.ndarray) -> float:\n",
    "        # return sum(abs(dn) * self.tick_size)\n",
    "        return abs(dn) * self.tick_size\n",
    "\n",
    "    def impact_cost(self, dn: np.ndarray) -> float:\n",
    "        # return sum(dn ** 2 * self.tick_size / self.lot_size)\n",
    "        return dn ** 2 * self.tick_size / self.lot_size\n",
    "    \n",
    "    def total_cost(self, dn: np.ndarray) -> float:\n",
    "        return self.spread_cost(dn) + self.impact_cost(dn)\n",
    "    \n",
    "    def delta_vt(\n",
    "        self, \n",
    "        action: int,\n",
    "        prices: float,\n",
    "    ):\n",
    "        shares = self._decode_action(action)\n",
    "        prev_shares = self.history['shares'][-1]\n",
    "        dn = shares - prev_shares\n",
    "        rate = prices / self.window[-1] - 1 if self.window[-1] > 0 else 0\n",
    "        return np.sum(prev_shares * self.window[-1] * rate) - self.total_cost(dn)\n",
    "    \n",
    "    def _decode_action(self, action: np.ndarray) -> np.ndarray:\n",
    "        return np.take(self.shares, action)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # def _plot_position(position, tick):\n",
    "        #     color = None\n",
    "        #     if position == Positions.Short:\n",
    "        #         color = 'red'\n",
    "        #     elif position == Positions.Long:\n",
    "        #         color = 'green'\n",
    "        #     if color:\n",
    "        #         plt.scatter(tick, self.prices[tick], color=color)\n",
    "\n",
    "        # if self._first_rendering:\n",
    "        #     self._first_rendering = False\n",
    "        #     plt.cla()\n",
    "        #     plt.plot(self.prices)\n",
    "        #     start_position = self.history['position_history'][self._start_tick]\n",
    "        #     _plot_position(start_position, self._start_tick)\n",
    "\n",
    "        # _plot_position(self._position, self._current_tick)\n",
    "\n",
    "        # plt.suptitle(\n",
    "        #     \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "        #     \"Total Profit: %.6f\" % self._total_profit\n",
    "        # )\n",
    "\n",
    "        # plt.pause(0.01)\n",
    "        pass\n",
    "\n",
    "\n",
    "    def render_all(self, mode='human'):\n",
    "        # window_ticks = np.arange(len(self.history['position_history']))\n",
    "        # plt.plot(self.prices)\n",
    "\n",
    "        # short_ticks = []\n",
    "        # long_ticks = []\n",
    "        # for i, tick in enumerate(window_ticks):\n",
    "        #     if self.history['position_history'][i] == Positions.Short:\n",
    "        #         short_ticks.append(tick)\n",
    "        #     elif self.history['position_history'][i] == Positions.Long:\n",
    "        #         long_ticks.append(tick)\n",
    "\n",
    "        # plt.plot(short_ticks, self.prices[short_ticks], 'ro')\n",
    "        # plt.plot(long_ticks, self.prices[long_ticks], 'go')\n",
    "\n",
    "        # plt.suptitle(\n",
    "        #     \"Total Reward: %.6f\" % self._total_reward + ' ~ ' +\n",
    "        #     \"Total Profit: %.6f\" % self._total_profit\n",
    "        # )\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def close(self):\n",
    "        # plt.close()\n",
    "        pass\n",
    "\n",
    "\n",
    "    def save_rendering(self, filepath):\n",
    "        # plt.savefig(filepath)\n",
    "        pass\n",
    "\n",
    "\n",
    "    def pause_rendering(self):\n",
    "        # plt.show()\n",
    "        pass\n",
    "\n",
    "    def _calculate_reward(self, delta_vt):\n",
    "        return delta_vt - self.kappa * (delta_vt ** 2)\n",
    "\n",
    "    def max_possible_profit(self):  # trade fees are ignored\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d493427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp data\n",
    "# price = np.load('price.pkl.npy')\n",
    "# df = pd.DataFrame()\n",
    "# df['A'] = price\n",
    "\n",
    "# env = TradingEnv(df, window_size=50, kappa=1e-4)\n",
    "# obs = env.reset()\n",
    "# done = False\n",
    "# while not done:\n",
    "#     action = env.action_space.sample()\n",
    "#     _, _, done, _ = env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1bafef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x2825edd06d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# temp data\n",
    "price = np.load('price.pkl.npy')\n",
    "df = pd.DataFrame()\n",
    "df['A'] = price\n",
    "\n",
    "env = TradingEnv(df, window_size=3, kappa=1e-4)\n",
    "obs = env.reset()\n",
    "\n",
    "model = DQN(\n",
    "    'MlpPolicy', \n",
    "    env=env, \n",
    "    learning_rate=0.001,\n",
    "    gamma=0.999,\n",
    "    exploration_initial_eps=0.1,\n",
    "    exploration_final_eps=0.1,\n",
    "    train_freq=1,\n",
    "    learning_starts=1000,\n",
    "    target_update_interval=1000,\n",
    "    tensorboard_log='log'\n",
    ")\n",
    "model.learn(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be968b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "mean, std = evaluate_policy(model, env, n_eval_episodes=1, render=True)\n",
    "print(f\"Mean reward: {mean:.2f} +/- {std: .2f}\")\n",
    "# pd.DataFrame(env.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f0ab7e5d89cbe175b1507231777ebebded5226bdde5cb0055cb23b58c7e2a9b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
